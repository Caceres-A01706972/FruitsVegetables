# -*- coding: utf-8 -*-
"""FruitsVegetables.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16VUVIWrCAAxw_bQn4-QJ2CRpsgw4HcBI

# **Clasificador Fruits and Vegetables**

### ***Objetivo:***

Desarrollar un clasificador de frutas y vegetales utilizando técnicas de aprendizaje automático.

Lo principal es clasificar imágenes estáticas de frutas y vegetales. Pero en futuras versiones se planea extender esta capacidad para clasificar en tiempo real utilizando la cámara, permitiendo llevar un registro de la cantidad de cada producto mostrado.

Esta funcionalidad está diseñada para facilitar el conteo y seguimiento de productos en un entorno de supermercado.

### ***Drive con el Dataset:***
[Dataset de Fruitas y Vegetales](https://drive.google.com/drive/folders/1Jkadebp3GhvkF-c1rBmxgevV6G_3diNX?usp=sharing)

### ***Nombre y Matricula:***

Ricardo Andrés Cáceres Villibord A01706972

## Conectando Google Drive y Configurango el directorio
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# Aqui dse debe de sustituir el path en donde fue guardada la carpeta del Dataset
# %cd "/content/drive/MyDrive/IA_8vo/Proyecto IA"
!ls

"""## Importando librerias necesarias"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from PIL import Image

"""## Directorios de Train, Test y Validation"""

base_dir = 'Dataset'
train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')
validation_dir = os.path.join(base_dir, 'validation')

"""## Para sacar las rutas de las imagenes y sus categorias"""

image_paths = []
categories = []

# Recorrer todas las carpetas (categorías) y añadir las imagenes a la lista
for category in os.listdir(train_dir):
    category_path = os.path.join(train_dir, category)
    if os.path.isdir(category_path):
        for img_name in os.listdir(category_path):
            if img_name.endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(category_path, img_name))
                categories.append(category)

# Ponerlo en un Dataframe para facil visualizacion
df = pd.DataFrame({
    'image_path': image_paths,
    'category': categories
})

df.head()

"""## Visualización random de como son las imagenes"""

# Seleccionar 5 imágenes aleatorias
random_indices = random.sample(range(len(image_paths)), 5)
random_images = [image_paths[i] for i in random_indices]
random_categories = [categories[i] for i in random_indices]

# Mostrar 5 random images con su label
plt.figure(figsize=(25, 10))
for i in range(5):
    img = Image.open(random_images[i])
    plt.subplot(1, 5, i + 1)
    plt.imshow(img)
    plt.title(random_categories[i], fontsize=20)
    plt.axis('off')

plt.tight_layout()
plt.show()

"""## Data Augmentation
Esto geenera nuevas imagenes en el ram mientras se entrena. (En cada epoca se va a usar una version modificada de la imagen)
"""

# Se define que transformaciones se le van a aplicar
train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 100,
    zoom_range = 0.3,
    horizontal_flip = True,
)

# Se define el generador de datos para el conjunto de validación (solo normalización)
validation_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Se define el generador de datos para el conjunto de prueba (solo normalización)
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

"""Se normaliza las imagenes de test y se generan con el mismo tamaño y el one-hot encoding"""

# Crear el generador de datos para el conjunto train
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (150,150),
    batch_size = 32,
    color_mode = 'rgb',
    class_mode = 'categorical' # Hace one-hot encoding para las categorias (0,0,1,0,0,0.....)
)

# Crear el generador de datos para el conjunto de validación
validation_generator = validation_datagen.flow_from_directory(
    validation_dir,          # Directorio de datos de validación
    target_size=(150, 150),  # Redimensionar las imágenes a 64x64 píxeles
    batch_size=32,            # Número de imágenes por lote
    color_mode = 'rgb',
    class_mode='categorical' # Clasificación categórica
)

# Crear el generador de datos para el conjunto de prueba
test_generator = test_datagen.flow_from_directory(
    test_dir,                # Directorio de datos de prueba
    target_size=(150, 150),  # Redimensionar las imágenes a 150x150 píxeles
    batch_size=32,           # Número de imágenes por lote
    color_mode = 'rgb',
    class_mode='categorical' # Clasificación categórica
)

"""## Visualización de Imagenes Aumentadas"""

# Visualizar algunas imágenes aumentadas del conjunto de entrenamiento
augmented_images = [train_generator[0][0][i] for i in range(5)]

# Mostrar las imágenes aumentadas
plt.figure(figsize=(15, 10))
for i in range(5):
    plt.subplot(1, 5, i + 1)
    plt.imshow(augmented_images[i])
    plt.title(f'Augmented Image {i+1}', fontsize=12)
    plt.axis('off')
plt.tight_layout()
plt.show()

"""## Siguientes pasos

*   Generación del modelo de entrenamiento
*   Entrenamiento
*   Evaluación de modelo
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)), # Primera capa convolucional
    MaxPooling2D((2, 2)),  # Primera capa de pooling
    Conv2D(64, (3, 3), activation='relu'),  # Segunda capa convolucional
    MaxPooling2D((2, 2)),  # Segunda capa de pooling
    Conv2D(128, (3, 3), activation='relu'), # Tercera capa convolucional
    MaxPooling2D((2, 2)),  # Tercera capa de pooling
    Flatten(),  # Aplanar la salida de la última capa de pooling
    Dense(512, activation='relu'),  # Capa densa con 512 neuronas
    Dropout(0.5),  # Regularización con dropout
    Dense(len(train_generator.class_indices), activation='softmax')  # Capa de salida
])

# Compilar el modelo
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Entrenar el modelo y guardar el historial del entrenamiento
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()
plt.title("Accuracy")
plt.show()

pd.DataFrame(history.history)[['loss','val_loss']].plot()
plt.title("Loss")
plt.show()

# Predict the label of the test_images
pred = model.predict(test_generator)
pred = np.argmax(pred,axis=1)

# Map the label
labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
pred = [labels[k] for k in pred]

y_test = [labels[k] for k in test_generator.classes]

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print(f'Accuracy on the test set: {100*acc:.2f}%')

# Guardar el modelo completo en el sistema de archivos temporal
model.save('fruit_vegetable_classifier_Simple.h5')

# Guardar el modelo en Google Drive
model_save_path = '/content/drive/MyDrive/IA_8vo/Proyecto IA/fruit_vegetable_classifier_Simple.h5'
model.save(model_save_path)