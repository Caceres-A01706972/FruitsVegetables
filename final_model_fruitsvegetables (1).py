# -*- coding: utf-8 -*-
"""Final Model FruitsVegetables.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ond8fw1lo_u-2mCnuRdksZ7g7jCddWyB

# **Clasificador Fruits and Vegetables**

### ***Objetivo:***

Desarrollar un clasificador de frutas y vegetales utilizando técnicas de aprendizaje automático.

Lo principal es clasificar imágenes estáticas de frutas y vegetales. Pero en futuras versiones se planea extender esta capacidad para clasificar en tiempo real utilizando la cámara, permitiendo llevar un registro de la cantidad de cada producto mostrado.

Esta funcionalidad está diseñada para facilitar el conteo y seguimiento de productos en un entorno de supermercado.

### ***Drive con el Dataset:***
[Dataset de Fruitas y Vegetales](https://drive.google.com/drive/folders/1Jkadebp3GhvkF-c1rBmxgevV6G_3diNX?usp=sharing)

### ***Nombre y Matricula:***

Ricardo Andrés Cáceres Villibord A01706972

## Conectando Google Drive y Configurango el directorio
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# Aqui dse debe de sustituir el path en donde fue guardada la carpeta del Dataset
# %cd "/content/drive/MyDrive/IA_8vo/Proyecto IA"
!ls

"""## Importando librerias necesarias"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
from PIL import Image

"""## Directorios de Train, Test y Validation"""

base_dir = 'Dataset'
train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')
validation_dir = os.path.join(base_dir, 'validation')

"""## Para sacar las rutas de las imagenes y sus categorias"""

def proc_img(directorio):
  image_paths = []
  categories = []

  # Recorrer todas las carpetas (categorías) y añadir las imagenes a la lista
  for category in os.listdir(directorio):
      category_path = os.path.join(directorio, category)
      if os.path.isdir(category_path):
          for img_name in os.listdir(category_path):
              if img_name.endswith(('.png', '.jpg', '.jpeg')):
                  image_paths.append(os.path.join(category_path, img_name))
                  categories.append(category)

  # Ponerlo en un Dataframe para facil visualizacion
  df = pd.DataFrame({
      'image_path': image_paths,
      'category': categories
  })

  return df

train_df = proc_img(train_dir)
test_df = proc_img(test_dir)
validation_df = proc_img(validation_dir)

print('-- Training set --\n')
print(f'Number of pictures: {train_df.shape[0]}\n')
print(f'Number of different labels: {len(train_df.category.unique())}\n')
print(f'Labels: {train_df.category.unique()}')

train_df.head(5)

"""## Visualización random de como son las imagenes"""

df_unique = train_df.copy().drop_duplicates(subset=["category"]).reset_index()

# Display some pictures of the dataset
fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(df_unique.image_path[i]))
    ax.set_title(df_unique.category[i], fontsize = 12)
plt.tight_layout(pad=0.5)
plt.show()

"""## Data Augmentation
Esto geenera nuevas imagenes en el ram mientras se entrena. (En cada epoca se va a usar una version modificada de la imagen)
"""

train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input
)

train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='image_path',
    y_col='category',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=0,
    rotation_range=30,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode="nearest"
)

val_images = train_generator.flow_from_dataframe(
    dataframe=validation_df,
    x_col='image_path',
    y_col='category',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=0,
    rotation_range=30,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode="nearest"
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='image_path',
    y_col='category',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

# Load the pretained model
pretrained_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)
pretrained_model.trainable = False

inputs = pretrained_model.input

x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)

outputs = tf.keras.layers.Dense(36, activation='softmax')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    validation_data=val_images,
    batch_size = 32,
    epochs=5,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=2,
            restore_best_weights=True
        )
    ]
)

pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()
plt.title("Accuracy")
plt.show()

pd.DataFrame(history.history)[['loss','val_loss']].plot()
plt.title("Loss")
plt.show()

# Predict the label of the test_images
pred = model.predict(test_images)
pred = np.argmax(pred,axis=1)

# Map the label
labels = (train_images.class_indices)
labels = dict((v,k) for k,v in labels.items())
pred = [labels[k] for k in pred]

y_test = [labels[k] for k in test_images.classes]

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print(f'Accuracy on the test set: {100*acc:.2f}%')

cr = classification_report(y_test, pred)
print('Classification Report:\n', cr)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cf_matrix = confusion_matrix(y_test, pred, normalize='true')
plt.figure(figsize = (15,10))
sns.heatmap(cf_matrix,
            annot=True,
            xticklabels = sorted(set(y_test)),
            yticklabels = sorted(set(y_test)),
            )
plt.title('Normalized Confusion Matrix')
plt.show()

# Número de imágenes a mostrar
num_images = 9

# Generar índices aleatorios
random_indices = np.random.choice(range(len(test_df)), size=num_images, replace=False)

# Crear la figura y los ejes
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15),
                         subplot_kw={'xticks': [], 'yticks': []})

# Mostrar las imágenes aleatorias con sus etiquetas verdaderas y predicciones
for ax, idx in zip(axes.flat, random_indices):
    ax.imshow(plt.imread(test_df.image_path.iloc[idx]))
    ax.set_title(f"True: {test_df.category.iloc[idx]}\nPredicted: {pred[idx]}")
plt.tight_layout()
plt.show()

# Guardar el modelo completo en el sistema de archivos temporal
model.save('fruit_vegetable_classifier_MobileNetV2.h5')

# Guardar el modelo en Google Drive
model_save_path = '/content/drive/MyDrive/IA_8vo/Proyecto IA/fruit_vegetable_classifier_MobileNetV2.h5'
model.save(model_save_path)

# Cargar el modelo guardado desde Google Drive
from tensorflow.keras.models import load_model
cnn = load_model('/content/drive/MyDrive/IA_8vo/Proyecto IA/fruit_vegetable_classifier_MobileNetV2.h5')

categories = train_df['category'].unique()
print(categories)

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
from google.colab import files
from PIL import Image


# Función para cargar y preprocesar la imagen
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))  # Cambia a 64x64 si es necesario
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalizar la imagen
    return img_array

# Pedir al usuario que cargue una imagen
uploaded = files.upload()

for img_path in uploaded.keys():
    # Preprocesar la imagen cargada
    img_array = load_and_preprocess_image(img_path)

    # Hacer la predicción
    prediction = cnn.predict(img_array)

    # Obtener la etiqueta de clase
    class_names = categories
    predicted_class = np.argmax(prediction, axis=1)
    predicted_class_name = class_names[predicted_class[0]]

    # Mostrar la imagen y la predicción
    plt.imshow(Image.open(img_path))
    plt.title(f'Predicción: {predicted_class_name}')
    plt.axis('off')
    plt.show()

    print(f'La imagen cargada es de la clase: {predicted_class_name}')