# キ Clasificador de Frutas y Vegetales ウ

## Descripci贸n del Proyecto 
El objetivo de este proyecto es desarrollar un clasificador de frutas y vegetales utilizando t茅cnicas de aprendizaje autom谩tico.

Lo principal es clasificar im谩genes est谩ticas de frutas y vegetales. Pero en futuras versiones se planea extender esta capacidad para clasificar en tiempo real utilizando la c谩mara, permitiendo llevar un registro de la cantidad de cada producto mostrado. 

Esta funcionalidad est谩 dise帽ada para facilitar el conteo y seguimiento de productos en un entorno de supermercado.

## Dataset 
El dataset utilizado contiene im谩genes de diversas frutas y vegetales organizadas en carpetas seg煤n su categor铆a. Los datos est谩n divididos en dos conjuntos principales:

- Conjunto de Entrenamiento: Utilizado para entrenar el modelo.
    - (Contiene 36 clases, 100 imagenes en cada clase)
- Conjunto de Prueba: Utilizado para evaluar el rendimiento del modelo.
    - (Contiene 36 clases, 10 imagenes en cada clase)
- Conjunto de Validaci贸n: Utilizado para ajustar los hiperpar谩metros del modelo y evaluar su rendimiento durante el entrenamiento sin influir en las decisiones de dise帽o del modelo.
    - (Contiene 36 clases, 10 imagenes cada uno)
  
Cada categor铆a de frutas y vegetales tiene su propia carpeta, y cada carpeta contiene varias im谩genes en formatos .png, .jpg o .jpeg.

El dataset se puede descargar desde el siguiente enlace: 
[Dataset de Frutas y Vegetales](https://drive.google.com/drive/folders/1Jkadebp3GhvkF-c1rBmxgevV6G_3diNX?usp=sharing)

El dataset original puede ser encontrado en el siguiente enlace:
[Dataset en Kaggle](https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition)

## Estructura del C贸digo (Hasta el 26 de mayo de 2024) 
- **Conexi贸n a Google Drive y Directorio**
- **Importar Librer铆as**
- **Directorio de Datos:** Se definen los directorios que contienen los datos tanto de entrenamiento como de prueba (Train, Test)
- **Visualizaci贸n del Dataset:** Mostrar ejemplos aleatorios de imagenes con sus categor铆as correspondientes.
- **Data Augmentation:** Se aplica Data Augmentation al conjunto de entrenamiento (Se aplican transformaciones como rotaci贸n, zoom,  horizontal_flip)
- **Primera Implementaci贸n del Modelo:** Definici贸n y compilaci贸n del modelo inicial.
- **Entrenamiento del Modelo:** Entrenar el modelo ocupando el conjunto de Train y el de Validation.
- **Visualizaci贸n del Rendimiento:** An谩lisis de los resultados del entrenamiento y evaluaci贸n del modelo para detectar overfitting o underfitting.
- **Guardar el Modelo:** Guardar el modelo entrenado para su uso futuro.

## Preprocesamiento y Data Augmentation 
Para mejorar el rendimiento del modelo y evitar el sobreajuste, se aplicaron t茅cnicas de preprocesamiento y data augmentation a los datos de entrenamiento. El preprocesamiento y la data augmentation son pasos cruciales en el desarrollo de modelos de deep learning, especialmente en tareas de clasificaci贸n de im谩genes.

### Normalizaci贸n
Para la normalizaci贸n de los valores de los p铆xeles, se utiliz贸 `ImageDataGenerator` de Keras con el par谩metro `rescale=1./255`. Esto escala los valores de los p铆xeles de [0, 255] a [0, 1], lo cual es beneficioso porque los modelos de redes neuronales tienden a converger m谩s r谩pido y de manera m谩s estable cuando los valores de entrada est谩n en un rango m谩s peque帽o y uniforme.

### Data Augmentation
La data augmentation se implement贸 usando diversas transformaciones para aumentar la variabilidad del conjunto de entrenamiento. Las transformaciones incluyeron rotaci贸n, zoom y volteo horizontal. Estas t茅cnicas ayudan al modelo a generalizar mejor al introducir variaciones que el modelo puede encontrar en datos no vistos durante el entrenamiento.

### Generadores de Datos
Se crearon generadores de datos para los conjuntos de entrenamiento, validaci贸n y prueba utilizando ImageDataGenerator. Estos generadores permiten cargar las im谩genes en lotes y aplicar las transformaciones definidas en tiempo real, optimizando as铆 el uso de memoria y el rendimiento del entrenamiento.


## Primera Implementaci贸n del Modelo 
La implementaci贸n del modelo se bas贸 en una arquitectura de red neuronal convolucional (CNN) por su eficiencia en problemas de clasificaci贸n de imagenes como lo es en el caso de este proyecto.
En la CNN se implementaron varias capas de convoluci贸n y pooling ara extraer las caracter铆sticas de las im谩genes, seguidas de capas densas para realizar la clasificaci贸n final.

### Estructura del Modelo
1. Capas Convolucionales y de Pooling:
    - Se agregaron 3 capas convolucionales. La primera de 32 filtros con una funci贸n de activaci贸n 'relu' (Rectified Linear Unit) se eligi贸 por su capacidad para introducir no linealidad, permitiendo al modelo aprender caracter铆sticas complejas. Esta capa es seguida por una capa de MaxPooling con un tama帽o de pool de 2x2 para reducir la dimensionalidad y extraer caracter铆sticas de manera m谩s eficiente. Las otras capas convolucionales se aumentaron los filtros para que se puedan aprender caracter铆sticas de mayor nivel.
2. Capas Densas y Dropout:
    - Una capa densa con la funci贸n de activaci贸n "relu". Esta capa ayuda para que en combinaci贸n con las caracter铆sticas aprendidas en las capas convolucionales, se pueda hacer la clasificaci贸n.
    - Se a帽adio una capa de Dropout seteada en 0.5 para prevenir el sobreajuste, una t茅cnica recomendada en el siguiente research paper: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf
3. Capa de Salida:
    - En la capa de salida se ocupa la funci贸n de activaci贸n "Softmax" para proporcionar una distribuci贸n de probabilidad sobre las diferentes clases de frutas y vegetales. Referencia Textbook: https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf

### Evaluaci贸n del Modelo 
- **Epoch 1/30**:
  - Loss: 3.4358 - Accuracy: 0.0704
  - Val_Loss: 2.8538 - Val_Accuracy: 0.2062

- **Epoch 30/30**:
  - Loss: 1.4369 - Accuracy: 0.5582
  - Val_Loss: 0.7331 - Val_Accuracy: 0.7937
<p align="center">
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/0f0d7a52-2b17-40d7-9772-b7d68b02bdd1" width="45%" />
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/e42aff90-14e7-4b58-afd0-53008fa531b4" width="45%" />
</p>

### An谩lisis del Rendimiento del Modelo
El entrenamiento mostr贸 una mejora continua en la precisi贸n tanto en el conjunto de entrenamiento como en el de validaci贸n.
- Inicialmente, se puede observar un underfitting inicial ya que la precisi贸n es muy baja en ambos conjuntos.
- Finalmente, se puede observar un progreso hacia el Overfitting ya que el aumento en la precisi贸n del Train junto con una tasa de mejora m谩s lenta en el conjunto de Validation. Esto significa que el modelo estaba empezando a hacer Overfitting.
    - El Overfitting significa que el modelo se esta ajustando demasiado a lso datos de Training, (podr铆amos decir que esta memorizando), esto afecta negativamente su rendimientoe en datos no vistos. Lo que en nuestra clasificaci贸n final cuando querramos darle una im谩gen cualquiera (sacada de internet, o una real) tendr谩 un rendimiento negativo incapaz de clasificar que fruta o vegetal es.

### Posibles Soluciones para Mejorar el Rendimiento 
1. Aumentar el Data Augmentation: Incrementar las transformaciones aplicadas a las im谩genes de entrenamiento para que el modelo vea una mayor variedad de datos.
2. Transfer Learning con MobileNet: Usar modelos preentrenados como MobileNet para mejorar el rendimiento del clasificador, aprovechando caracter铆sticas ya aprendidas de grandes datasets.
    - **Se explorar谩 esta opci贸n de Soluci贸n para mejorar el Modelo**.

## Siguientes Pasos
- **Segunda Implementaci贸n del Modelo**: Explorar la implementaci贸n de Transfer Learning con MobileNet.
- Implementar Interfaz para facilitar el uso del modelo ya entrenado.

