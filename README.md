# ü•≠üçé Clasificador de Frutas y Vegetales ü•¶üçå

## Descripci√≥n del Proyecto üíª
El objetivo de este proyecto es desarrollar un clasificador de frutas y vegetales utilizando t√©cnicas de aprendizaje autom√°tico.

Lo principal es clasificar im√°genes est√°ticas de frutas y vegetales.

Esta funcionalidad est√° dise√±ada para facilitar el conteo y seguimiento de productos en un entorno de supermercado.

## Dataset üìä
El dataset utilizado contiene im√°genes de diversas frutas y vegetales organizadas en carpetas seg√∫n su categor√≠a. Los datos est√°n divididos en dos conjuntos principales:

- Conjunto de Entrenamiento: Utilizado para entrenar el modelo.
    - (Contiene 36 clases, 100 imagenes en cada clase)
- Conjunto de Prueba: Utilizado para evaluar el rendimiento del modelo.
    - (Contiene 36 clases, 10 imagenes en cada clase)
- Conjunto de Validaci√≥n: Utilizado para ajustar los hiperpar√°metros del modelo y evaluar su rendimiento durante el entrenamiento sin influir en las decisiones de dise√±o del modelo.
    - (Contiene 36 clases, 10 imagenes cada uno)
  
Cada categor√≠a de frutas y vegetales tiene su propia carpeta, y cada carpeta contiene varias im√°genes en formatos .png, .jpg o .jpeg.

El dataset se puede descargar desde el siguiente enlace: 
[Dataset de Frutas y Vegetales](https://drive.google.com/drive/folders/1Jkadebp3GhvkF-c1rBmxgevV6G_3diNX?usp=sharing)

El dataset original puede ser encontrado en el siguiente enlace:
[Dataset en Kaggle](https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition)

## Estructura del C√≥digo (Hasta el 26 de mayo de 2024) üìÅ
- **Conexi√≥n a Google Drive y Directorio**
- **Importar Librer√≠as**
- **Directorio de Datos:** Se definen los directorios que contienen los datos tanto de entrenamiento como de prueba (Train, Test)
- **Visualizaci√≥n del Dataset:** Mostrar ejemplos aleatorios de imagenes con sus categor√≠as correspondientes.
- **Data Augmentation:** Se aplica Data Augmentation al conjunto de entrenamiento (Se aplican transformaciones como rotaci√≥n, zoom,  horizontal_flip)
- **Primera Implementaci√≥n del Modelo:** Definici√≥n y compilaci√≥n del modelo inicial.
- **Entrenamiento del Modelo:** Entrenar el modelo ocupando el conjunto de Train y el de Validation.
- **Visualizaci√≥n del Rendimiento:** An√°lisis de los resultados del entrenamiento y evaluaci√≥n del modelo para detectar overfitting o underfitting.
- **Guardar el Modelo:** Guardar el modelo entrenado para su uso futuro.

## Preprocesamiento y Data Augmentation üìà
Para mejorar el rendimiento del modelo y evitar el sobreajuste, se aplicaron t√©cnicas de preprocesamiento y data augmentation a los datos de entrenamiento. El preprocesamiento y la data augmentation son pasos cruciales en el desarrollo de modelos de deep learning, especialmente en tareas de clasificaci√≥n de im√°genes.

### Normalizaci√≥n
Para la normalizaci√≥n de los valores de los p√≠xeles, se utiliz√≥ `ImageDataGenerator` de Keras con el par√°metro `rescale=1./255`. Esto escala los valores de los p√≠xeles de [0, 255] a [0, 1], lo cual es beneficioso porque los modelos de redes neuronales tienden a converger m√°s r√°pido y de manera m√°s estable cuando los valores de entrada est√°n en un rango m√°s peque√±o y uniforme.

### Data Augmentation
La data augmentation se implement√≥ usando diversas transformaciones para aumentar la variabilidad del conjunto de entrenamiento. Las transformaciones incluyeron rotaci√≥n, zoom y volteo horizontal. Estas t√©cnicas ayudan al modelo a generalizar mejor al introducir variaciones que el modelo puede encontrar en datos no vistos durante el entrenamiento.

### Generadores de Datos
Se crearon generadores de datos para los conjuntos de entrenamiento, validaci√≥n y prueba utilizando ImageDataGenerator. Estos generadores permiten cargar las im√°genes en lotes y aplicar las transformaciones definidas en tiempo real, optimizando as√≠ el uso de memoria y el rendimiento del entrenamiento.


## Primera Implementaci√≥n del Modelo üß†
La implementaci√≥n del modelo se bas√≥ en una arquitectura de red neuronal convolucional (CNN) por su eficiencia en problemas de clasificaci√≥n de imagenes como lo es en el caso de este proyecto.
En la CNN se implementaron varias capas de convoluci√≥n y pooling ara extraer las caracter√≠sticas de las im√°genes, seguidas de capas densas para realizar la clasificaci√≥n final.

### Estructura del Modelo
1. Capas Convolucionales y de Pooling:
    - Se agregaron 3 capas convolucionales. La primera de 32 filtros con una funci√≥n de activaci√≥n `relu` (Rectified Linear Unit) se eligi√≥ por su capacidad para introducir no linealidad, permitiendo al modelo aprender caracter√≠sticas complejas. Esta capa es seguida por una capa de MaxPooling con un tama√±o de pool de 2x2 para reducir la dimensionalidad y extraer caracter√≠sticas de manera m√°s eficiente. Las otras capas convolucionales se aumentaron los filtros para que se puedan aprender caracter√≠sticas de mayor nivel.
2. Capas Densas y Dropout:
    - Una capa densa con la funci√≥n de activaci√≥n `relu`. Esta capa ayuda para que en combinaci√≥n con las caracter√≠sticas aprendidas en las capas convolucionales, se pueda hacer la clasificaci√≥n.
    - Se a√±adio una capa de Dropout seteada en 0.5 para prevenir el sobreajuste, una t√©cnica recomendada en el siguiente research paper: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf
3. Capa de Salida:
    - En la capa de salida se ocupa la funci√≥n de activaci√≥n `Softmax` para proporcionar una distribuci√≥n de probabilidad sobre las diferentes clases de frutas y vegetales. Referencia Textbook: https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf

### Evaluaci√≥n del Modelo üìä
Durante la evaluaci√≥n del modelo, se ha seguido la m√©trica de evaluaci√≥n de `Accuracy`, ya que es la t√©cnica utilizada en el paper de Pathak, Rupali. (2021). CLASSIFICATION OF FRUITS USING CONVOLUTIONAL NEURAL NETWORK AND TRANSFER LEARNING MODELS. https://www.researchgate.net/publication/364254116_CLASSIFICATION_OF_FRUITS_USING_CONVOLUTIONAL_NEURAL_NETWORK_AND_TRANSFER_LEARNING_MODELS


- **Epoch 1/30**:
  - Loss: 3.4358 - Accuracy: 0.0704
  - Val_Loss: 2.8538 - Val_Accuracy: 0.2062

- **Epoch 30/30**:
  - Loss: 1.4369 - Accuracy: 0.5582
  - Val_Loss: 0.7331 - Val_Accuracy: 0.7937
<p align="center">
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/0f0d7a52-2b17-40d7-9772-b7d68b02bdd1" width="45%" />
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/e42aff90-14e7-4b58-afd0-53008fa531b4" width="45%" />
</p>

- **Conjunto de Test**
    - Accuracy Test Set: 2.79%

### An√°lisis del Rendimiento del Modelo
El entrenamiento mostr√≥ una mejora continua en la precisi√≥n tanto en el conjunto de entrenamiento como en el de validaci√≥n.
- Inicialmente, se puede observar un underfitting inicial ya que la precisi√≥n es muy baja en ambos conjuntos.
- Finalmente, se puede observar un progreso hacia el Overfitting ya que el aumento en la precisi√≥n del Train junto con una tasa de mejora m√°s lenta en el conjunto de Validation. Esto significa que el modelo estaba empezando a hacer Overfitting.
    - El Overfitting significa que el modelo se esta ajustando demasiado a lso datos de Training, (podr√≠amos decir que esta memorizando), esto afecta negativamente su rendimientoe en datos no vistos. Lo que en nuestra clasificaci√≥n final cuando querramos darle una im√°gen cualquiera (sacada de internet, o una real) tendr√° un rendimiento negativo incapaz de clasificar que fruta o vegetal es.

### Posibles Soluciones para Mejorar el Rendimiento üöÄ
1. Aumentar el Data Augmentation: Incrementar las transformaciones aplicadas a las im√°genes de entrenamiento para que el modelo vea una mayor variedad de datos.
2. Transfer Learning con MobileNet: Usar modelos preentrenados como MobileNet para mejorar el rendimiento del clasificador, aprovechando caracter√≠sticas ya aprendidas de grandes datasets.
    - **Se explorar√° esta opci√≥n de Soluci√≥n para mejorar el Modelo**.

## Segunda Implementaci√≥n del Modelo üß†

### Preprocesado y Data Augmentation üñºÔ∏è
El **data augmentation** se aplic√≥ al conjunto de entrenamiento para aumentar la diversidad de las im√°genes de entrenamiento y ayudar al modelo a generalizar mejor. Las t√©cnicas aplicadas incluyen:

- **Rescale**: Los valores de los p√≠xeles se escalaron a un rango de [0, 1] dividiendo por 255.
- **Rotation**: Rotaci√≥n aleatoria de las im√°genes en un rango de 30 grados.
- **Zoom**: Zoom aleatorio en un rango de 15%.
- **Width Shift**: Desplazamiento horizontal aleatorio en un rango de 20% del ancho total de la imagen.
- **Height Shift**: Desplazamiento vertical aleatorio en un rango de 20% del alto total de la imagen.
- **Shear**: Transformaci√≥n de corte (shear) en un rango de 15%.
- **Horizontal Flip**: Inversi√≥n horizontal aleatoria de las im√°genes.
- **Fill Mode**: Llenado de los p√≠xeles vac√≠os con el valor m√°s cercano.
  
Para los conjuntos de validaci√≥n y prueba, no se aplicaron t√©cnicas de data augmentation. Solo se **reescalaron** los valores de los p√≠xeles a un rango de [0, 1] para asegurar que las im√°genes de validaci√≥n y prueba tengan la misma escala que las de entrenamiento.

### Estructura del Modelo

1. **Capas Convolucionales y de Pooling**:
    - **Primera Capa Convolucional**:
        - `Conv2D(32, (3, 3), activation="relu", input_shape=(224, 224, 3))`: La primera capa convolucional tiene 32 filtros de tama√±o 3x3 y utiliza la funci√≥n de activaci√≥n `relu` (Rectified Linear Unit), que introduce no linealidad, permitiendo al modelo aprender caracter√≠sticas complejas. La capa de entrada espera im√°genes de tama√±o 224x224 con 3 canales de color (RGB).
        - `MaxPooling2D((2, 2))`: Esta capa de pooling reduce las dimensiones espaciales de la imagen (224x224 a 112x112), disminuyendo la complejidad computacional y ayudando a controlar el sobreajuste.
    - **Segunda Capa Convolucional**:
        - `Conv2D(64, (3, 3), activation="relu")`: La segunda capa convolucional tiene 64 filtros de tama√±o 3x3 y utiliza la funci√≥n de activaci√≥n `relu`.
        - `MaxPooling2D((2, 2))`: Otra capa de pooling para reducir las dimensiones espaciales (112x112 a 56x56).
    - **Tercera Capa Convolucional**:
        - `Conv2D(128, (3, 3), activation="relu")`: La tercera capa convolucional tiene 128 filtros de tama√±o 3x3 y utiliza la funci√≥n de activaci√≥n `relu`.
        - `MaxPooling2D((2, 2))`: La capa de pooling reduce a√∫n m√°s las dimensiones espaciales (56x56 a 28x28).
    - **Cuarta Capa Convolucional**:
        - `Conv2D(256, (3, 3), activation="relu")`: La cuarta capa convolucional tiene 256 filtros de tama√±o 3x3 y utiliza la funci√≥n de activaci√≥n `relu`.
        - `MaxPooling2D((2, 2))`: La √∫ltima capa de pooling reduce las dimensiones espaciales a (28x28 a 14x14).

2. **Capas Densas**:
    - `Flatten()`: Aplana la salida tridimensional de la √∫ltima capa convolucional, prepar√°ndola para las capas densas.
    - `Dense(512, activation="relu")`: Una capa densa con 512 unidades y la funci√≥n de activaci√≥n `relu`. Esta capa aprende de las caracter√≠sticas extra√≠das por las capas convolucionales y ayuda en la clasificaci√≥n.

3. **Capa de Salida**:
    - `Dense(36, activation="softmax")`: La capa de salida tiene 36 unidades (correspondientes a las 36 clases de frutas y vegetales) y utiliza la funci√≥n de activaci√≥n `softmax` para proporcionar una distribuci√≥n de probabilidad sobre las diferentes clases. Referencia Textbook: https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf
      
### Evaluaci√≥n del Modelo üìä
Durante la evaluaci√≥n del modelo, se ha seguido la m√©trica de evaluaci√≥n de `Accuracy`, ya que es la t√©cnica utilizada en el paper de Pathak, Rupali. (2021). CLASSIFICATION OF FRUITS USING CONVOLUTIONAL NEURAL NETWORK AND TRANSFER LEARNING MODELS. https://www.researchgate.net/publication/364254116_CLASSIFICATION_OF_FRUITS_USING_CONVOLUTIONAL_NEURAL_NETWORK_AND_TRANSFER_LEARNING_MODELS

- **Epoch 1/15**:
  - Loss: 3.1972 - Accuracy: 0.1128
  - Val_Loss: 2.5543 - Val_Accuracy: 0.2232

- **Epoch 15/15**:
  - Loss: 1.5531 - Accuracy: 0.5148
  - Val_Loss: 1.2925 - Val_Accuracy: 0.5884

- **Test Set**:
    - Loss: 1.2927 - Accuracy: 0.5892 

<p align="center">
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/09681f3c-97e5-478d-be42-1c2d87969547" width="45%" />
  <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/dedc6e0f-d88c-4711-9ff1-4b0c80816f41" width="45%" />
</p>

### An√°lisis del Rendimiento del Modelo
Observamos que la brecha entre el Accuracy del conjunto de Train y del conjunto de Validation se ha reducido en comparaci√≥n con la implementaci√≥n del primer modelo. Esto sugiere que el modelo ha mejorado su capacidad para generalizar a datos nuevos y no est√° sobreajustando tanto como antes.

La precisi√≥n final del modelo en el conjunto de Validation es del 58.84%, lo que indica un rendimiento razonable en la clasificaci√≥n de frutas y vegetales.
Dado que la precisi√≥n del conjunto de Train y del conjunto de Validation son parecidas al final del entrenamiento, no parece haber signos claros de overfitting o underfitting en este punto.

### Posibles Soluciones para Mejorar el Rendimiento üöÄ
1. Aumentar el n√∫mero de √©pocas en el entrenamiento.
2. Transfer Learning con MobileNet: Usar modelos preentrenados como MobileNet para mejorar el rendimiento del clasificador, aprovechando caracter√≠sticas ya aprendidas de grandes datasets.
    - **Se explorar√° esta opci√≥n de Soluci√≥n para mejorar el Modelo**.

## Siguientes Pasos
- Implementaci√≥n de modelo con Transfer Learning de MobileNetV2

## Implementaci√≥n Final del Modelo utilizando MobileNetV2 üß†üöÄ
Para esta implementaci√≥n, se utiliz√≥ el modelo MobileNetV2 preentrenado en ImageNet. Este modelo aprovecha las caracter√≠sticas aprendidas de grandes datasets y adapta el modelo a la tarea espec√≠fica de clasificaci√≥n de frutas y vegetales.

### Preprocesado y Data Augmentation üñºÔ∏è
El `preprocesado` y la `data augmentation` se realizaron de la siguiente manera:

- **Rescale**: Los valores de los p√≠xeles se escalaron a un rango de [0, 1].
- **Data Augmentation**: Rotaci√≥n, zoom, desplazamiento horizontal y vertical, transformaci√≥n de corte y volteo horizontal.

### Estructura del Modelo

1. **MobileNetV2 como Base:**
    - Se utiliz√≥ el modelo MobileNetV2 preentrenado en ImageNet, excluyendo las capas superiores (`include_top=False`). Este modelo se configur√≥ como no entrenable (`trainable=False`) para mantener las caracter√≠sticas preaprendidas.
2. **Capas Adicionales:**
    - `Dense(128, activation="relu"):` Dos capas densas con 128 unidades y la funci√≥n de activaci√≥n relu para aprender nuevas caracter√≠sticas espec√≠ficas del dataset.
    - `Dense(36, activation="softmax")`: La capa de salida con 36 unidades y la funci√≥n de activaci√≥n softmax para la clasificaci√≥n de las frutas y vegetales. Referencia Textbook: https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf

### Evaluaci√≥n del Modelo üìä
Durante la evaluaci√≥n del modelo, se ha seguido la m√©trica de evaluaci√≥n de `Accuracy`, ya que es la t√©cnica utilizada en el paper de Pathak, Rupali. (2021). CLASSIFICATION OF FRUITS USING CONVOLUTIONAL NEURAL NETWORK AND TRANSFER LEARNING MODELS. https://www.researchgate.net/publication/364254116_CLASSIFICATION_OF_FRUITS_USING_CONVOLUTIONAL_NEURAL_NETWORK_AND_TRANSFER_LEARNING_MODELS

- **Epoch 1/5**:
  - Loss: 1.6736 - Accuracy: 0.5543
  - Val_Loss: 0.3880 - Val_Accuracy: 0.9014

- **Epoch 5/5**:
  - Loss: 0.1412 - Accuracy: 0.9563
  - Val_Loss: 0.1477 - Val_Accuracy: 0.9623

- **Test Set**:
    - Accuracy on the test set: 96.32%

<p align="center">
    <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/2b98e5e3-37c7-4c8b-abfb-112351083254" width="45%" />
    <img src="https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/582bc20c-b358-42a3-a76f-80a112c80794" width="45%" />
</p>

### An√°lisis del Rendimiento del Modelo
El modelo muestra una mejora constante en la precisi√≥n tanto en el conjunto de entrenamiento como en el de validaci√≥n a lo largo de las √©pocas. Los resultados indican una mejora significativa en el rendimiento del modelo a lo largo del tiempo. La precisi√≥n final en el conjunto de validaci√≥n fue del 96.23%, lo que indica una capacidad de generalizaci√≥n robusta.

En resumen, el modelo muestra un excelente rendimiento tanto en los datos de entrenamiento como en los de validaci√≥n, sin indicios significativos de overfitting o underfitting. La alta precisi√≥n en el conjunto de prueba (96.32%) confirma la capacidad del modelo para generalizar bien a datos no vistos durante el entrenamiento.

### Matriz de Confusi√≥n
![image](https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/bb367b7c-12eb-40ef-81bb-fc2797813fb8)

## Clasification Report
![image](https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/977bceac-b1f7-4ac4-bda7-fe587b1715ee)


### Utilizar Modelo
![image](https://github.com/Caceres-A01706972/FruitsVegetables/assets/83652905/64cd5897-de39-4195-84ae-982546cae80b)


